{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import lucid_kietzmannlab.modelzoo.vision_models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import lucid_kietzmannlab.optvis.objectives as objectives\n",
    "import lucid_kietzmannlab.optvis.render as render\n",
    "from ipywidgets import interact, Dropdown, IntSlider\n",
    "from IPython.display import clear_output\n",
    "from lucid_kietzmannlab.modelzoo.vision_models import get_layer_names_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/vkapoor/Downloads/training_seed_05/model.ckpt_epoch89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 22:00:47.772064: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/vkapoor/Downloads/training_seed_05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tower_0/alexnet_v2/conv1/Conv2D': <tf.Tensor 'tower_0/alexnet_v2/conv1/Conv2D:0' shape=(32, 64, 54, 54) dtype=float32>,\n",
       " 'tower_0/alexnet_v2/conv2/Conv2D': <tf.Tensor 'tower_0/alexnet_v2/conv2/Conv2D:0' shape=(32, 192, 26, 26) dtype=float32>,\n",
       " 'tower_0/alexnet_v2/conv3/Conv2D': <tf.Tensor 'tower_0/alexnet_v2/conv3/Conv2D:0' shape=(32, 384, 12, 12) dtype=float32>,\n",
       " 'tower_0/alexnet_v2/conv4/Conv2D': <tf.Tensor 'tower_0/alexnet_v2/conv4/Conv2D:0' shape=(32, 384, 12, 12) dtype=float32>,\n",
       " 'tower_0/alexnet_v2/conv5/Conv2D': <tf.Tensor 'tower_0/alexnet_v2/conv5/Conv2D:0' shape=(32, 256, 12, 12) dtype=float32>,\n",
       " 'tower_0/alexnet_v2/fc6/Conv2D': <tf.Tensor 'tower_0/alexnet_v2/fc6/Conv2D:0' shape=(32, 4096, 1, 1) dtype=float32>,\n",
       " 'tower_0/alexnet_v2/fc7/Conv2D': <tf.Tensor 'tower_0/alexnet_v2/fc7/Conv2D:0' shape=(32, 4096, 1, 1) dtype=float32>,\n",
       " 'tower_0/alexnet_v2/fc8/Conv2D': <tf.Tensor 'tower_0/alexnet_v2/fc8/Conv2D:0' shape=(32, 565, 1, 1) dtype=float32>,\n",
       " 'tower_1/alexnet_v2/conv1/Conv2D': <tf.Tensor 'tower_1/alexnet_v2/conv1/Conv2D:0' shape=(32, 64, 54, 54) dtype=float32>,\n",
       " 'tower_1/alexnet_v2/conv2/Conv2D': <tf.Tensor 'tower_1/alexnet_v2/conv2/Conv2D:0' shape=(32, 192, 26, 26) dtype=float32>,\n",
       " 'tower_1/alexnet_v2/conv3/Conv2D': <tf.Tensor 'tower_1/alexnet_v2/conv3/Conv2D:0' shape=(32, 384, 12, 12) dtype=float32>,\n",
       " 'tower_1/alexnet_v2/conv4/Conv2D': <tf.Tensor 'tower_1/alexnet_v2/conv4/Conv2D:0' shape=(32, 384, 12, 12) dtype=float32>,\n",
       " 'tower_1/alexnet_v2/conv5/Conv2D': <tf.Tensor 'tower_1/alexnet_v2/conv5/Conv2D:0' shape=(32, 256, 12, 12) dtype=float32>,\n",
       " 'tower_1/alexnet_v2/fc6/Conv2D': <tf.Tensor 'tower_1/alexnet_v2/fc6/Conv2D:0' shape=(32, 4096, 1, 1) dtype=float32>,\n",
       " 'tower_1/alexnet_v2/fc7/Conv2D': <tf.Tensor 'tower_1/alexnet_v2/fc7/Conv2D:0' shape=(32, 4096, 1, 1) dtype=float32>,\n",
       " 'tower_1/alexnet_v2/fc8/Conv2D': <tf.Tensor 'tower_1/alexnet_v2/fc8/Conv2D:0' shape=(32, 565, 1, 1) dtype=float32>,\n",
       " 'tower_2/alexnet_v2/conv1/Conv2D': <tf.Tensor 'tower_2/alexnet_v2/conv1/Conv2D:0' shape=(32, 64, 54, 54) dtype=float32>,\n",
       " 'tower_2/alexnet_v2/conv2/Conv2D': <tf.Tensor 'tower_2/alexnet_v2/conv2/Conv2D:0' shape=(32, 192, 26, 26) dtype=float32>,\n",
       " 'tower_2/alexnet_v2/conv3/Conv2D': <tf.Tensor 'tower_2/alexnet_v2/conv3/Conv2D:0' shape=(32, 384, 12, 12) dtype=float32>,\n",
       " 'tower_2/alexnet_v2/conv4/Conv2D': <tf.Tensor 'tower_2/alexnet_v2/conv4/Conv2D:0' shape=(32, 384, 12, 12) dtype=float32>,\n",
       " 'tower_2/alexnet_v2/conv5/Conv2D': <tf.Tensor 'tower_2/alexnet_v2/conv5/Conv2D:0' shape=(32, 256, 12, 12) dtype=float32>,\n",
       " 'tower_2/alexnet_v2/fc6/Conv2D': <tf.Tensor 'tower_2/alexnet_v2/fc6/Conv2D:0' shape=(32, 4096, 1, 1) dtype=float32>,\n",
       " 'tower_2/alexnet_v2/fc7/Conv2D': <tf.Tensor 'tower_2/alexnet_v2/fc7/Conv2D:0' shape=(32, 4096, 1, 1) dtype=float32>,\n",
       " 'tower_2/alexnet_v2/fc8/Conv2D': <tf.Tensor 'tower_2/alexnet_v2/fc8/Conv2D:0' shape=(32, 565, 1, 1) dtype=float32>,\n",
       " 'tower_3/alexnet_v2/conv1/Conv2D': <tf.Tensor 'tower_3/alexnet_v2/conv1/Conv2D:0' shape=(32, 64, 54, 54) dtype=float32>,\n",
       " 'tower_3/alexnet_v2/conv2/Conv2D': <tf.Tensor 'tower_3/alexnet_v2/conv2/Conv2D:0' shape=(32, 192, 26, 26) dtype=float32>,\n",
       " 'tower_3/alexnet_v2/conv3/Conv2D': <tf.Tensor 'tower_3/alexnet_v2/conv3/Conv2D:0' shape=(32, 384, 12, 12) dtype=float32>,\n",
       " 'tower_3/alexnet_v2/conv4/Conv2D': <tf.Tensor 'tower_3/alexnet_v2/conv4/Conv2D:0' shape=(32, 384, 12, 12) dtype=float32>,\n",
       " 'tower_3/alexnet_v2/conv5/Conv2D': <tf.Tensor 'tower_3/alexnet_v2/conv5/Conv2D:0' shape=(32, 256, 12, 12) dtype=float32>,\n",
       " 'tower_3/alexnet_v2/fc6/Conv2D': <tf.Tensor 'tower_3/alexnet_v2/fc6/Conv2D:0' shape=(32, 4096, 1, 1) dtype=float32>,\n",
       " 'tower_3/alexnet_v2/fc7/Conv2D': <tf.Tensor 'tower_3/alexnet_v2/fc7/Conv2D:0' shape=(32, 4096, 1, 1) dtype=float32>,\n",
       " 'tower_3/alexnet_v2/fc8/Conv2D': <tf.Tensor 'tower_3/alexnet_v2/fc8/Conv2D:0' shape=(32, 565, 1, 1) dtype=float32>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint_dir = \"/Users/vkapoor/Downloads/training_seed_05\"\n",
    "model_checkpoint = \"model.ckpt_epoch89\"\n",
    "model = models.EcoAlexModel(model_checkpoint_dir, model_checkpoint)\n",
    "model.load_model_layers()\n",
    "get_layer_names_tensors(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name_list = [layer_info[\"name\"] for layer_info in model.layers]\n",
    "\n",
    "with tf.Graph().as_default() as graph:\n",
    "    # Import the model\n",
    "    tf.import_graph_def(model.graph_def, name='')\n",
    "\n",
    "    # Get the shape of each tensor\n",
    "    layer_shape_dict = {}\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        for layer_name in layer_name_list:\n",
    "            try:\n",
    "                tensor_shape = sess.graph.get_tensor_by_name(f'{layer_name}:0').shape\n",
    "                \n",
    "                if tensor_shape != ():\n",
    "                  \n",
    "                    if tensor_shape[0] is None:\n",
    "                       \n",
    "                       layer_shape_dict[layer_name] = tensor_shape\n",
    "            except KeyError:\n",
    "                # Handle the case where the tensor is not found\n",
    "                layer_shape_dict[layer_name] = None\n",
    "C = lambda neuron: objectives.channel(*neuron)    \n",
    "def visualize(layer_name, channel):\n",
    "    # Check if the layer exists in the shape dictionary\n",
    "    if layer_name in layer_shape_dict:\n",
    "        # Check if the selected channel is within bounds\n",
    "        print(layer_shape_dict[layer_name])\n",
    "        max_channel = layer_shape_dict[layer_name][-1] - 1\n",
    "        if 0 <= channel <= max_channel:\n",
    "            clear_output(wait=True)\n",
    "            # Render visualization for the selected layer and channel\n",
    "            #try:\n",
    "            _ = render.render_vis(model, C((layer_name, channel)), scope = '', reverse = False)\n",
    "            #except Exception:\n",
    "            #    print('No gradients for this layer')   \n",
    "\n",
    "def visualize_all():\n",
    "    # Check if the layer exists in the shape dictionary\n",
    "    layer_name = current_dropdown_value({'new': layer_dropdown.value})\n",
    "    print(layer_name)\n",
    "    if layer_name in layer_shape_dict:\n",
    "            # Check if the selected channel is within bounds\n",
    "            try:\n",
    "               image_channel = {} \n",
    "               for channel in tqdm(range(channel_slider.max)):    \n",
    "                  images = render.render_vis(model, C((layer_name, channel)), verbose = False)\n",
    "                  image_channel[channel] = images \n",
    "            except Exception:\n",
    "                print('No gradients for this layer')    \n",
    "    return image_channel            \n",
    "                              \n",
    "def plot_images(image_channel):\n",
    "    channels = list(image_channel.keys())\n",
    "    for i in range(0, len(channels), 3):\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))  \n",
    "        for j in range(3):\n",
    "            channel_index = i + j\n",
    "            if channel_index < len(channels):\n",
    "                channel = channels[channel_index]\n",
    "                images = image_channel[channel]\n",
    "                try:\n",
    "                    axs[j].imshow(images[0][0,:])  \n",
    "                    axs[j].set_title(f\"Channel {channel}\")\n",
    "                    axs[j].axis('off')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error plotting channel {channel}: {e}\")\n",
    "                    axs[j].axis('off')\n",
    "                    axs[j].text(0.5, 0.5, 'Error', ha='center', va='center')\n",
    "            else:\n",
    "                axs[j].axis('off')  \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "# Create dropdown menu for layer selection\n",
    "layer_dropdown = Dropdown(options=list(layer_shape_dict.keys()), description='Layer:')\n",
    "\n",
    "# Create slider for channel selection\n",
    "channel_slider = IntSlider(min=0, max=0, description='Channel:')\n",
    "        \n",
    "        \n",
    "def update_channel_slider(change):\n",
    "    layer_name = change.new\n",
    "    if layer_name in layer_shape_dict:\n",
    "        \n",
    "        max_channel = layer_shape_dict[layer_name][-1] - 1\n",
    "        channel_slider.max = max_channel\n",
    "        \n",
    "        \n",
    "def current_slider_value(*args):\n",
    "    return channel_slider.value\n",
    "\n",
    "\n",
    "def current_dropdown_value(change):\n",
    "    return change['new']\n",
    "\n",
    "\n",
    "channel_slider.observe(current_slider_value, names='value')\n",
    "layer_dropdown.observe(current_dropdown_value, names='value')\n",
    "        \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db97e1d562324bd3bc91c2fb16c8fa15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Layer:', options=('tower_0/alexnet_v2/conv1/Conv2D', 'tower_0/alexâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.visualize(layer_name, channel)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dropdown.observe(update_channel_slider, names='value')\n",
    "\n",
    "# Create an interactive visualization\n",
    "interact(visualize, layer_name=layer_dropdown, channel=channel_slider)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channel = visualize_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if image_channel:\n",
    "    plot_images(image_channel)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'tower_0/alexnet_v2/pool1/MaxPool' defined at (most recent call last):\nNode: 'tower_0/alexnet_v2/pool1/MaxPool'\nDefault MaxPoolingOp only supports NHWC on device type CPU\n\t [[{{node tower_0/alexnet_v2/pool1/MaxPool}}]]\n\nOriginal stack trace for 'tower_0/alexnet_v2/pool1/MaxPool':\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/client/session.py:1402\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1402\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/client/session.py:1385\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/client/session.py:1478\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1477\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1478\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Default MaxPoolingOp only supports NHWC on device type CPU\n\t [[{{node tower_0/alexnet_v2/pool1/MaxPool}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_forward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_tensor_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtower_0/alexnet_v2/conv4/Conv2D:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/modelzoo/vision_models.py:563\u001b[0m, in \u001b[0;36mEcoAlexModel.perform_forward_pass\u001b[0;34m(self, output_tensor_name)\u001b[0m\n\u001b[1;32m    558\u001b[0m output_tensor \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mget_tensor_by_name(\n\u001b[1;32m    559\u001b[0m     output_tensor_name\n\u001b[1;32m    560\u001b[0m )  \u001b[38;5;66;03m# Example output tensor\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# Run the session to get the output\u001b[39;00m\n\u001b[0;32m--> 563\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_input\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput values:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/client/session.py:972\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    975\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/client/session.py:1215\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1215\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/client/session.py:1395\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1392\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/client/session.py:1421\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly supports NHWC tensor format\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message:\n\u001b[1;32m   1417\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1418\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mby modifying the config for creating the session eg.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1419\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msession_config.graph_options.rewrite_options.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1420\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_meta_optimizer = True\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1421\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'tower_0/alexnet_v2/pool1/MaxPool' defined at (most recent call last):\nNode: 'tower_0/alexnet_v2/pool1/MaxPool'\nDefault MaxPoolingOp only supports NHWC on device type CPU\n\t [[{{node tower_0/alexnet_v2/pool1/MaxPool}}]]\n\nOriginal stack trace for 'tower_0/alexnet_v2/pool1/MaxPool':\n"
     ]
    }
   ],
   "source": [
    "model.perform_forward_pass(output_tensor_name='tower_0/alexnet_v2/conv4/Conv2D:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucidenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
