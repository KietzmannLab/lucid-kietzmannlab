{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vkapoor/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import lucid_kietzmannlab.modelzoo.vision_models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import lucid_kietzmannlab.optvis.objectives as objectives\n",
    "import lucid_kietzmannlab.optvis.render as render\n",
    "from ipywidgets import interact, Dropdown, IntSlider\n",
    "tf.disable_v2_behavior()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/vkapoor/Downloads/training_seed_06/model.ckpt_epoch89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 13:40:29.220516: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/vkapoor/Downloads/training_seed_06\n",
      "Layer: tower_0/alexnet_v2/conv1/Conv2D, Shape: (32, 64, 54, 54)\n",
      "Layer: tower_0/alexnet_v2/conv2/Conv2D, Shape: (32, 192, 26, 26)\n",
      "Layer: tower_0/alexnet_v2/conv3/Conv2D, Shape: (32, 384, 12, 12)\n",
      "Layer: tower_0/alexnet_v2/conv4/Conv2D, Shape: (32, 384, 12, 12)\n",
      "Layer: tower_0/alexnet_v2/conv5/Conv2D, Shape: (32, 256, 12, 12)\n",
      "Layer: tower_0/alexnet_v2/fc6/Conv2D, Shape: (32, 4096, 1, 1)\n",
      "Layer: tower_0/alexnet_v2/fc7/Conv2D, Shape: (32, 4096, 1, 1)\n",
      "Layer: tower_0/alexnet_v2/fc8/Conv2D, Shape: (32, 565, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_dir = \"/Users/vkapoor/Downloads/training_seed_06\"\n",
    "model_checkpoint = \"model.ckpt_epoch89\"\n",
    "model, graph,  layer_shape_dict = models.load_ecoset_model_seeds(model_checkpoint_dir, model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = lambda neuron: objectives.channel(*neuron)    \n",
    "def visualize(layer_name, channel):\n",
    "    # Check if the layer exists in the shape dictionary\n",
    "    if layer_name in layer_shape_dict:\n",
    "        # Check if the selected channel is within bounds\n",
    "        print(layer_shape_dict[layer_name])\n",
    "        max_channel = layer_shape_dict[layer_name][-1] - 1\n",
    "        if 0 <= channel <= max_channel:\n",
    "            #clear_output(wait=True)\n",
    "            # Render visualization for the selected layer and channel\n",
    "            #try:\n",
    "            _ = render.render_vis(model, C((layer_name, channel)), scope='')\n",
    "            #except Exception:\n",
    "            #    print('No gradients for this layer')   \n",
    "\n",
    "def visualize_all():\n",
    "    # Check if the layer exists in the shape dictionary\n",
    "    layer_name = current_dropdown_value({'new': layer_dropdown.value})\n",
    "    print(layer_name)\n",
    "    if layer_name in layer_shape_dict:\n",
    "            # Check if the selected channel is within bounds\n",
    "            try:\n",
    "               image_channel = {} \n",
    "               for channel in tqdm(range(channel_slider.max)):    \n",
    "                  images = render.render_vis(model, C((layer_name, channel)), verbose = False)\n",
    "                  image_channel[channel] = images \n",
    "            except Exception:\n",
    "                print('No gradients for this layer')    \n",
    "    return image_channel   \n",
    "\n",
    "\n",
    "# Create dropdown menu for layer selection\n",
    "layer_dropdown = Dropdown(options=list(layer_shape_dict.keys()), description='Layer:')\n",
    "\n",
    "# Create slider for channel selection\n",
    "channel_slider = IntSlider(min=0, max=0, description='Channel:')\n",
    "        \n",
    "        \n",
    "def update_channel_slider(change):\n",
    "    layer_name = change.new\n",
    "    if layer_name in layer_shape_dict:\n",
    "        print(layer_name)\n",
    "        print(layer_shape_dict[layer_name])\n",
    "        max_channel = layer_shape_dict[layer_name][-1] - 1\n",
    "        channel_slider.max = max_channel\n",
    "        \n",
    "        \n",
    "def current_slider_value(*args):\n",
    "    return channel_slider.value\n",
    "\n",
    "\n",
    "def current_dropdown_value(change):\n",
    "    return change['new']\n",
    "\n",
    "\n",
    "channel_slider.observe(current_slider_value, names='value')\n",
    "layer_dropdown.observe(current_dropdown_value, names='value')\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name 'import/tower_0/alexnet_v2/conv1/Conv2D:0' refers to a Tensor which does not exist. The operation, 'import/tower_0/alexnet_v2/conv1/Conv2D', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:2925\u001b[0m, in \u001b[0;36mGraph._as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2924\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2925\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_operation_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mKeyError\u001b[0m: ''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m array_4d_random \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom(shape)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray_4d_random\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/modelzoo/vision_base.py:634\u001b[0m, in \u001b[0;36mModel.get_activations\u001b[0;34m(self, layer, examples, batch_size, dtype, ind_shape, center_only)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_activations\u001b[39m(\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    598\u001b[0m     layer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m     center_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    604\u001b[0m ):\n\u001b[1;32m    605\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Collect center activtions of a layer over an n-dimensional array of images.\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    Note: this is mostly intended for large synthetic families of images, where\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;124;03m      A numpy array of shape [ind1, ind2, ..., layer_channels]\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_activations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mind_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mind_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenter_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/modelzoo/vision_base.py:272\u001b[0m, in \u001b[0;36m_get_activations\u001b[0;34m(model, layer, examples, batch_size, dtype, ind_shape, center_only)\u001b[0m\n\u001b[1;32m    266\u001b[0m examples_enumerated \u001b[38;5;241m=\u001b[39m recursive_enumerate_nd(\n\u001b[1;32m    267\u001b[0m     examples,\n\u001b[1;32m    268\u001b[0m     stop_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    269\u001b[0m )\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# Get responses\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_activations_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexamples_enumerated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mind_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mind_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenter_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/modelzoo/vision_base.py:164\u001b[0m, in \u001b[0;36mget_activations_iter\u001b[0;34m(model, layer, generator, reducer, batch_size, dtype, ind_shape, center_only)\u001b[0m\n\u001b[1;32m    162\u001b[0m t_img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mplaceholder(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m    163\u001b[0m T \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mimport_graph(t_img)\n\u001b[0;32m--> 164\u001b[0m t_layer \u001b[38;5;241m=\u001b[39m \u001b[43mT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    167\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/modelzoo/vision_base.py:414\u001b[0m, in \u001b[0;36mModel.import_graph.<locals>.T\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mget_tensor_by_name(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscope\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensor_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mscope\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:3036\u001b[0m, in \u001b[0;36mGraph.get_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   3032\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor names are strings (or similar), not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   3033\u001b[0m                   \u001b[38;5;28mtype\u001b[39m(name)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   3034\u001b[0m tensor \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   3035\u001b[0m     tensor_lib\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m-> 3036\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_graph_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_operation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m )\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:2885\u001b[0m, in \u001b[0;36mGraph.as_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2882\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_as_graph_element_locked(obj, allow_tensor, allow_operation)\n\u001b[1;32m   2884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 2885\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_graph_element_locked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_operation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:2927\u001b[0m, in \u001b[0;36mGraph._as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2925\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_operation_by_name(op_name)\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 2927\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   2928\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m refers to a Tensor which does not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2929\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexist. The operation, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, does not exist in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2930\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(name), \u001b[38;5;28mrepr\u001b[39m(op_name))\n\u001b[1;32m   2931\u001b[0m   ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m   2933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2934\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39moutputs[out_n]\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'import/tower_0/alexnet_v2/conv1/Conv2D:0' refers to a Tensor which does not exist. The operation, 'import/tower_0/alexnet_v2/conv1/Conv2D', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "lname = 'tower_0/alexnet_v2/conv1/Conv2D'\n",
    "shape = (1,224, 224,3)\n",
    "array_4d_random = np.random.random(shape)\n",
    "model.get_activations(lname, array_4d_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 54, 54)\n",
      "tower_0/alexnet_v2/conv1/Conv2D []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"The name 'None:0' refers to a Tensor which does not exist. The operation, 'None', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:2925\u001b[0m, in \u001b[0;36mGraph._as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2924\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2925\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_operation_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mKeyError\u001b[0m: ''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m lname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtower_0/alexnet_v2/conv1/Conv2D\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvisualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mvisualize\u001b[0;34m(layer_name, channel)\u001b[0m\n\u001b[1;32m      7\u001b[0m max_channel \u001b[38;5;241m=\u001b[39m layer_shape_dict[layer_name][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m channel \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_channel:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#clear_output(wait=True)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Render visualization for the selected layer and channel\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#try:\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mrender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_vis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/optvis/render.py:92\u001b[0m, in \u001b[0;36mrender_vis\u001b[0;34m(model, objective_f, param_f, optimizer, transforms, thresholds, print_objectives, verbose, scope)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Flexible optimization-base feature vis.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mThere's a lot of ways one might wish to customize otpimization-based\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m  multiple channel visualizations stacked on top of each other.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGraph()\u001b[38;5;241m.\u001b[39mas_default() \u001b[38;5;28;01mas\u001b[39;00m graph, tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m sess:\n\u001b[0;32m---> 92\u001b[0m     T \u001b[38;5;241m=\u001b[39m \u001b[43mmake_vis_T\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     print_objective_func \u001b[38;5;241m=\u001b[39m make_print_objective_func(print_objectives, T)\n\u001b[1;32m     96\u001b[0m     loss, vis_op, t_image \u001b[38;5;241m=\u001b[39m T(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m), T(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvis_op\u001b[39m\u001b[38;5;124m\"\u001b[39m), T(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/optvis/render.py:176\u001b[0m, in \u001b[0;36mmake_vis_T\u001b[0;34m(model, objective_f, param_f, optimizer, transforms, scope)\u001b[0m\n\u001b[1;32m    173\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m make_optimizer(optimizer, [])\n\u001b[1;32m    175\u001b[0m T \u001b[38;5;241m=\u001b[39m import_model(model, transform_f(t_image), t_image, scope\u001b[38;5;241m=\u001b[39mscope)\n\u001b[0;32m--> 176\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mobjective_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m global_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;241m0\u001b[39m, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_step\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    179\u001b[0m vis_op \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mminimize(\u001b[38;5;241m-\u001b[39mloss, global_step\u001b[38;5;241m=\u001b[39mglobal_step)\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/optvis/objectives.py:112\u001b[0m, in \u001b[0;36mObjective.__call__\u001b[0;34m(self, T)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, T):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/optvis/objectives.py:160\u001b[0m, in \u001b[0;36mchannel.<locals>.<lambda>\u001b[0;34m(T)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Visualize a single channel\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m T: tf\u001b[38;5;241m.\u001b[39mreduce_mean(\u001b[43mT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, n_channel])\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m T: tf\u001b[38;5;241m.\u001b[39mreduce_mean(T(layer)[batch, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, n_channel])\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/optvis/render.py:276\u001b[0m, in \u001b[0;36mimport_model.<locals>.T\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    274\u001b[0m strings \u001b[38;5;241m=\u001b[39m [op\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m t_image\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mget_operations()]\n\u001b[1;32m    275\u001b[0m closest_op_name \u001b[38;5;241m=\u001b[39m find_closest_string(strings, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensor_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mclosest_op_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:3036\u001b[0m, in \u001b[0;36mGraph.get_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   3032\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor names are strings (or similar), not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   3033\u001b[0m                   \u001b[38;5;28mtype\u001b[39m(name)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   3034\u001b[0m tensor \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   3035\u001b[0m     tensor_lib\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m-> 3036\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_graph_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_operation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m )\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:2885\u001b[0m, in \u001b[0;36mGraph.as_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2882\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_as_graph_element_locked(obj, allow_tensor, allow_operation)\n\u001b[1;32m   2884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 2885\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_graph_element_locked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_operation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:2927\u001b[0m, in \u001b[0;36mGraph._as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2925\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_operation_by_name(op_name)\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 2927\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   2928\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m refers to a Tensor which does not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2929\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexist. The operation, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, does not exist in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2930\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(name), \u001b[38;5;28mrepr\u001b[39m(op_name))\n\u001b[1;32m   2931\u001b[0m   ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m   2933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2934\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39moutputs[out_n]\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'None:0' refers to a Tensor which does not exist. The operation, 'None', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "lname = 'tower_0/alexnet_v2/conv1/Conv2D'\n",
    "visualize(lname, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dropdown.observe(update_channel_slider, names='value')\n",
    "\n",
    "# Create an interactive visualization\n",
    "interact(visualize, layer_name=layer_dropdown, channel=channel_slider)     \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucidenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
