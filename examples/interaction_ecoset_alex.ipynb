{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vkapoor/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import lucid_kietzmannlab.modelzoo.vision_models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import lucid_kietzmannlab.modelzoo.vision_models as models\n",
    "import lucid_kietzmannlab.optvis.objectives as objectives\n",
    "import lucid_kietzmannlab.optvis.render as render\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import interact, Dropdown, IntSlider\n",
    "tf.disable_v2_behavior()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/vkapoor/Downloads/training_seed_05/model.ckpt_epoch89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 08:31:33.256759: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/vkapoor/Downloads/training_seed_05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vkapoor/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_dir = \"/Users/vkapoor/Downloads/training_seed_05\"\n",
    "model_checkpoint = \"model.ckpt_epoch89\"\n",
    "model, graph, logits, activations, weights, layer_shape_dict = models.load_ecoset_model_seeds(model_checkpoint_dir, model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: alexnet_v2/conv1/Conv2D, Shape: (?, 54, 54, 64)\n",
      "Layer: alexnet_v2/conv2/Conv2D, Shape: (?, 26, 26, 192)\n",
      "Layer: alexnet_v2/conv3/Conv2D, Shape: (?, 12, 12, 384)\n",
      "Layer: alexnet_v2/conv4/Conv2D, Shape: (?, 12, 12, 384)\n",
      "Layer: alexnet_v2/conv5/Conv2D, Shape: (?, 12, 12, 256)\n",
      "Layer: alexnet_v2/fc6/Conv2D, Shape: (?, 1, 1, 4096)\n",
      "Layer: alexnet_v2/fc7/Conv2D, Shape: (?, 1, 1, 4096)\n",
      "Layer: alexnet_v2/fc8/Conv2D, Shape: (?, 1, 1, 565)\n"
     ]
    }
   ],
   "source": [
    "for layer, shape in layer_shape_dict.items():\n",
    "    print(f'Layer: {layer}, Shape: {shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = lambda neuron: objectives.channel(*neuron)    \n",
    "def visualize(layer_name, channel):\n",
    "    # Check if the layer exists in the shape dictionary\n",
    "    if layer_name in layer_shape_dict:\n",
    "        # Check if the selected channel is within bounds\n",
    "        print(layer_shape_dict[layer_name])\n",
    "        max_channel = layer_shape_dict[layer_name][-1] - 1\n",
    "        if 0 <= channel <= max_channel:\n",
    "            #clear_output(wait=True)\n",
    "            # Render visualization for the selected layer and channel\n",
    "            #try:\n",
    "            _ = render.render_vis(model, C((layer_name, channel)), scope='alexnet_v2')\n",
    "            #except Exception:\n",
    "            #    print('No gradients for this layer')   \n",
    "\n",
    "def visualize_all():\n",
    "    # Check if the layer exists in the shape dictionary\n",
    "    layer_name = current_dropdown_value({'new': layer_dropdown.value})\n",
    "    print(layer_name)\n",
    "    if layer_name in layer_shape_dict:\n",
    "            # Check if the selected channel is within bounds\n",
    "            try:\n",
    "               image_channel = {} \n",
    "               for channel in tqdm(range(channel_slider.max)):    \n",
    "                  images = render.render_vis(model, C((layer_name, channel)), verbose = False)\n",
    "                  image_channel[channel] = images \n",
    "            except Exception:\n",
    "                print('No gradients for this layer')    \n",
    "    return image_channel   \n",
    "\n",
    "\n",
    "# Create dropdown menu for layer selection\n",
    "layer_dropdown = Dropdown(options=list(layer_shape_dict.keys()), description='Layer:')\n",
    "\n",
    "# Create slider for channel selection\n",
    "channel_slider = IntSlider(min=0, max=0, description='Channel:')\n",
    "        \n",
    "        \n",
    "def update_channel_slider(change):\n",
    "    layer_name = change.new\n",
    "    if layer_name in layer_shape_dict:\n",
    "        print(layer_name)\n",
    "        print(layer_shape_dict[layer_name])\n",
    "        max_channel = layer_shape_dict[layer_name][-1] - 1\n",
    "        channel_slider.max = max_channel\n",
    "        \n",
    "        \n",
    "def current_slider_value(*args):\n",
    "    return channel_slider.value\n",
    "\n",
    "\n",
    "def current_dropdown_value(change):\n",
    "    return change['new']\n",
    "\n",
    "\n",
    "channel_slider.observe(current_slider_value, names='value')\n",
    "layer_dropdown.observe(current_dropdown_value, names='value')\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da661697bc74317a972711280646d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Layer:', options=('alexnet_v2/conv1/Conv2D', 'alexnet_v2/conv2/Conâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.visualize(layer_name, channel)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dropdown.observe(update_channel_slider, names='value')\n",
    "\n",
    "# Create an interactive visualization\n",
    "interact(visualize, layer_name=layer_dropdown, channel=channel_slider)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 54, 54, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 08:31:45.835540: W tensorflow/core/common_runtime/graph_constructor.cc:1595] Importing a graph with a lower producer version 38 into an existing graph with producer version 1766. Shape inference will have run different parts of the graph with different producer versions.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can not squeeze dim[3], expected a dimension of 1, got 3 for '{{node alexnet_v2/tower_0/alexnet_v2/fc8/squeezed}} = Squeeze[T=DT_FLOAT, squeeze_dims=[2, 3]](alexnet_v2/tower_0/alexnet_v2/fc8/BiasAdd)' with input shapes: [32,565,?,3].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/framework/importer.py:524\u001b[0m, in \u001b[0;36m_import_graph_def_internal\u001b[0;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list, propagate_device_spec)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39m_c_graph\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mas\u001b[39;00m c_graph:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 524\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_import_graphdef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_def_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m results \u001b[38;5;241m=\u001b[39m c_api_util\u001b[38;5;241m.\u001b[39mScopedTFImportGraphDefResults(results)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Can not squeeze dim[3], expected a dimension of 1, got 3 for '{{node alexnet_v2/tower_0/alexnet_v2/fc8/squeezed}} = Squeeze[T=DT_FLOAT, squeeze_dims=[2, 3]](alexnet_v2/tower_0/alexnet_v2/fc8/BiasAdd)' with input shapes: [32,565,?,3].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m lname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malexnet_v2/conv1/Conv2D\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvisualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36mvisualize\u001b[0;34m(layer_name, channel)\u001b[0m\n\u001b[1;32m      7\u001b[0m max_channel \u001b[38;5;241m=\u001b[39m layer_shape_dict[layer_name][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m channel \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_channel:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#clear_output(wait=True)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Render visualization for the selected layer and channel\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#try:\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mrender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_vis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malexnet_v2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/optvis/render.py:92\u001b[0m, in \u001b[0;36mrender_vis\u001b[0;34m(model, objective_f, param_f, optimizer, transforms, thresholds, print_objectives, verbose, scope)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Flexible optimization-base feature vis.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mThere's a lot of ways one might wish to customize otpimization-based\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m  multiple channel visualizations stacked on top of each other.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGraph()\u001b[38;5;241m.\u001b[39mas_default() \u001b[38;5;28;01mas\u001b[39;00m graph, tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m sess:\n\u001b[0;32m---> 92\u001b[0m     T \u001b[38;5;241m=\u001b[39m \u001b[43mmake_vis_T\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     print_objective_func \u001b[38;5;241m=\u001b[39m make_print_objective_func(print_objectives, T)\n\u001b[1;32m     96\u001b[0m     loss, vis_op, t_image \u001b[38;5;241m=\u001b[39m T(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m), T(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvis_op\u001b[39m\u001b[38;5;124m\"\u001b[39m), T(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/optvis/render.py:175\u001b[0m, in \u001b[0;36mmake_vis_T\u001b[0;34m(model, objective_f, param_f, optimizer, transforms, scope)\u001b[0m\n\u001b[1;32m    172\u001b[0m transform_f \u001b[38;5;241m=\u001b[39m make_transform_f(transforms)\n\u001b[1;32m    173\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m make_optimizer(optimizer, [])\n\u001b[0;32m--> 175\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[43mimport_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_image\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m loss \u001b[38;5;241m=\u001b[39m objective_f(T)\n\u001b[1;32m    178\u001b[0m global_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;241m0\u001b[39m, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_step\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/optvis/render.py:261\u001b[0m, in \u001b[0;36mimport_model\u001b[0;34m(model, t_image, t_image_raw, scope)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_model\u001b[39m(model, t_image, t_image_raw, scope\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 261\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforget_xy_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mT\u001b[39m(layer):\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/modelzoo/vision_models.py:270\u001b[0m, in \u001b[0;36mEcoAlexModel.import_graph\u001b[0;34m(self, t_input, scope, forget_xy_shape, input_map)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     final_input_map\u001b[38;5;241m.\u001b[39mupdate(input_map)\n\u001b[0;32m--> 270\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_graph_def\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_input_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_import(scope)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mT\u001b[39m(layer):\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/util/deprecation.py:588\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    581\u001b[0m       _log_deprecation(\n\u001b[1;32m    582\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    583\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    587\u001b[0m           instructions)\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/framework/importer.py:411\u001b[0m, in \u001b[0;36mimport_graph_def\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Imports the graph from `graph_def` into the current default `Graph`.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03mThis function provides a way to import a serialized TensorFlow\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m    it refers to an unknown tensor).\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m op_dict\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_import_graph_def_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_elements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_elements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproducer_op_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproducer_op_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/framework/importer.py:528\u001b[0m, in \u001b[0;36m_import_graph_def_internal\u001b[0;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list, propagate_device_spec)\u001b[0m\n\u001b[1;32m    525\u001b[0m   results \u001b[38;5;241m=\u001b[39m c_api_util\u001b[38;5;241m.\u001b[39mScopedTFImportGraphDefResults(results)\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    527\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    530\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_oss:\n",
      "\u001b[0;31mValueError\u001b[0m: Can not squeeze dim[3], expected a dimension of 1, got 3 for '{{node alexnet_v2/tower_0/alexnet_v2/fc8/squeezed}} = Squeeze[T=DT_FLOAT, squeeze_dims=[2, 3]](alexnet_v2/tower_0/alexnet_v2/fc8/BiasAdd)' with input shapes: [32,565,?,3]."
     ]
    }
   ],
   "source": [
    "lname = 'alexnet_v2/conv1/Conv2D'\n",
    "visualize(lname, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucidenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
