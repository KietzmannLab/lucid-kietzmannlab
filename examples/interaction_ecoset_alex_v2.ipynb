{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import lucid_kietzmannlab.modelzoo.vision_models as models\n",
    "from ipywidgets import interact, Dropdown, IntSlider\n",
    "from lucid_kietzmannlab.utils import interactive_visualization, batch_visualization, plot_images\n",
    "tf.compat.v1.disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model with name /Users/vkapoor/Downloads/models/AlexNet/training_seed_05/model.ckpt_epoch89\n",
      "INFO:tensorflow:Restoring parameters from /Users/vkapoor/Downloads/models/AlexNet/training_seed_05/model.ckpt_epoch89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 20:17:51.701389: W tensorflow/core/common_runtime/graph_constructor.cc:1595] Importing a graph with a lower producer version 38 into an existing graph with producer version 1766. Shape inference will have run different parts of the graph with different producer versions.\n",
      "2024-06-12 20:17:53.863898: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-06-12 20:17:55.776369: W tensorflow/c/c_api.cc:305] Operation '{name:'alexnet_v2/fc8/biases/Momentum/Assign' id:1952 op device:{requested: '', assigned: ''} def:{{{node alexnet_v2/fc8/biases/Momentum/Assign}} = Assign[T=DT_FLOAT, _class=[\"loc:@alexnet_v2/fc8/biases\"], _has_manual_control_dependencies=true, use_locking=true, validate_shape=true](alexnet_v2/fc8/biases/Momentum, alexnet_v2/fc8/biases/Momentum/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_dir=\"/Users/vkapoor/Downloads/models/AlexNet/training_seed_05\"\n",
    "training_seed = 5\n",
    "model = models.AlexNetv2(model_checkpoint_dir=model_checkpoint_dir, training_seed = training_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_shape_dict = model.layer_shape_dict\n",
    "def visualize(layer_name, channel):\n",
    "    interactive_visualization(model,layer_name, channel, scope = '', channels_first = True)   \n",
    "\n",
    "def visualize_all():\n",
    "    layer_name = current_dropdown_value({'new': layer_dropdown.value})\n",
    "    image_channel = batch_visualization(model, layer_name, channel_slider, scope = '', channels_first = True)\n",
    "    return image_channel              \n",
    "                              \n",
    "\n",
    "        \n",
    "# Create dropdown menu for layer selection\n",
    "layer_dropdown = Dropdown(options=list(layer_shape_dict.keys()), description='Layer:')\n",
    "\n",
    "# Create slider for channel selection\n",
    "channel_slider = IntSlider(min=0, max=0, description='Channel:')\n",
    "        \n",
    "        \n",
    "def update_channel_slider(change):\n",
    "    layer_name = change.new\n",
    "    if layer_name in layer_shape_dict:\n",
    "        \n",
    "        max_channel = layer_shape_dict[layer_name][-1] - 1\n",
    "        channel_slider.max = max_channel\n",
    "        \n",
    "        \n",
    "def current_slider_value(*args):\n",
    "    return channel_slider.value\n",
    "\n",
    "\n",
    "def current_dropdown_value(change):\n",
    "    return change['new']\n",
    "\n",
    "\n",
    "channel_slider.observe(current_slider_value, names='value')\n",
    "layer_dropdown.observe(current_dropdown_value, names='value')\n",
    "        \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a773c144dbf4f1c9de812594ec74535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Layer:', options=('tower_0/alexnet_v2/conv1/Conv2D', 'tower_0/alexâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.visualize(layer_name, channel)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dropdown.observe(update_channel_slider, names='value')\n",
    "\n",
    "# Create an interactive visualization\n",
    "interact(visualize, layer_name=layer_dropdown, channel=channel_slider)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channel = visualize_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if image_channel:\n",
    "    plot_images(image_channel)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_shape_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 20:18:11.796131: W tensorflow/core/common_runtime/graph_constructor.cc:1595] Importing a graph with a lower producer version 38 into an existing graph with producer version 1766. Shape inference will have run different parts of the graph with different producer versions.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Variable:0' shape=(2, 128, 3, 65) dtype=float32>\"] and loss Tensor(\"Neg:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvisualize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malexnet_v2/conv1/weights\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m, in \u001b[0;36mvisualize\u001b[0;34m(layer_name, channel)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize\u001b[39m(layer_name, channel):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43minteractive_visualization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_shape_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscope\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/utils.py:82\u001b[0m, in \u001b[0;36minteractive_visualization\u001b[0;34m(model, layer_name, channel, layer_shape_dict, scope, channels_first)\u001b[0m\n\u001b[1;32m     80\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Render visualization for the selected layer and channel\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mrender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_vis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/optvis/render.py:92\u001b[0m, in \u001b[0;36mrender_vis\u001b[0;34m(model, objective_f, param_f, optimizer, transforms, thresholds, print_objectives, verbose, scope, channels_first)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Flexible optimization-base feature vis.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mThere's a lot of ways one might wish to customize otpimization-based\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m  multiple channel visualizations stacked on top of each other.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGraph()\u001b[38;5;241m.\u001b[39mas_default() \u001b[38;5;28;01mas\u001b[39;00m graph, tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m sess:\n\u001b[0;32m---> 92\u001b[0m     T \u001b[38;5;241m=\u001b[39m \u001b[43mmake_vis_T\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjective_f\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparam_f\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     print_objective_func \u001b[38;5;241m=\u001b[39m make_print_objective_func(print_objectives, T)\n\u001b[1;32m    102\u001b[0m     loss, vis_op, t_image \u001b[38;5;241m=\u001b[39m T(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m), T(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvis_op\u001b[39m\u001b[38;5;124m\"\u001b[39m), T(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/optvis/render.py:187\u001b[0m, in \u001b[0;36mmake_vis_T\u001b[0;34m(model, objective_f, param_f, optimizer, transforms, scope, channels_first)\u001b[0m\n\u001b[1;32m    184\u001b[0m loss \u001b[38;5;241m=\u001b[39m objective_f(T)\n\u001b[1;32m    186\u001b[0m global_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;241m0\u001b[39m, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_step\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 187\u001b[0m vis_op \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m local_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlocals\u001b[39m()\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# pylint: enable=unused-variable\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/training/optimizer.py:480\u001b[0m, in \u001b[0;36mOptimizer.minimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    478\u001b[0m vars_with_grad \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mfor\u001b[39;00m g, v \u001b[38;5;129;01min\u001b[39;00m grads_and_vars \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vars_with_grad:\n\u001b[0;32m--> 480\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo gradients provided for any variable, check your graph for ops\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m that do not support gradients, between variables \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and loss \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    483\u001b[0m       ([\u001b[38;5;28mstr\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m _, v \u001b[38;5;129;01min\u001b[39;00m grads_and_vars], loss))\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars, global_step\u001b[38;5;241m=\u001b[39mglobal_step,\n\u001b[1;32m    486\u001b[0m                             name\u001b[38;5;241m=\u001b[39mname)\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Variable:0' shape=(2, 128, 3, 65) dtype=float32>\"] and loss Tensor(\"Neg:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": [
    "visualize('alexnet_v2/conv1/weights',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11, 3, 64) 64\n"
     ]
    }
   ],
   "source": [
    "layer_name = 'alexnet_v2/conv1/weights'\n",
    "graph = tf.compat.v1.get_default_graph()\n",
    "tensor = graph.get_tensor_by_name(f\"{layer_name}:0\")\n",
    "tensor_shape = tensor.shape\n",
    "print(tensor_shape, tensor_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.compat.v1.get_default_graph()\n",
    "for op in graph.operations:\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = tf.get_default_graph()\n",
    "inputs_placeholder = graph.get_tensor_by_name('Placeholder:0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3, 227, 227])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_placeholder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'alexnet_v2/conv1/weights:0' shape=(11, 11, 3, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/conv1/biases:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/conv2/weights:0' shape=(5, 5, 64, 192) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/conv2/biases:0' shape=(192,) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/conv3/weights:0' shape=(3, 3, 192, 384) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/conv3/biases:0' shape=(384,) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/conv4/weights:0' shape=(3, 3, 384, 384) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/conv4/biases:0' shape=(384,) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/conv5/weights:0' shape=(3, 3, 384, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/conv5/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/fc6/weights:0' shape=(5, 5, 256, 4096) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/fc6/biases:0' shape=(4096,) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/fc7/weights:0' shape=(1, 1, 4096, 4096) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/fc7/biases:0' shape=(4096,) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/fc8/weights:0' shape=(1, 1, 4096, 565) dtype=float32_ref>,\n",
       " <tf.Variable 'alexnet_v2/fc8/biases:0' shape=(565,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_placeholder = graph.get_tensor_by_name('alexnet_v2/conv1/weights:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([11, 11, 3, 64])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_placeholder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in graph.get_operations():\n",
    "        try:\n",
    "          if graph.get_tensor_by_name(f'{op.name}:0').shape[1] == 565: \n",
    "             print(op.name, graph.get_tensor_by_name(f'{op.name}:0').shape)\n",
    "        except:\n",
    "            pass     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as graph:\n",
    "    tf.import_graph_def(model.graph_def, name=\"\")\n",
    "    writer = tf.summary.FileWriter('AlexNetv2', graph)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucidenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
