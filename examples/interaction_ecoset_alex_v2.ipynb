{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import lucid_kietzmannlab.modelzoo.vision_models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import lucid_kietzmannlab.optvis.objectives as objectives\n",
    "import lucid_kietzmannlab.optvis.render as render\n",
    "from ipywidgets import interact, Dropdown, IntSlider\n",
    "from IPython.display import clear_output\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/vkapoor/Downloads/models/AlexNet/training_seed_05/model.ckpt_epoch89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 18:11:34.767788: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vkapoor/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/modelzoo/vision_models.py:340: convert_variables_to_constants (from tensorflow.python.framework.convert_to_constants) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /Users/vkapoor/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/framework/convert_to_constants.py:946: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "property 'graph_def' of 'AlexNetv2' object has no setter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_checkpoint_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/vkapoor/Downloads/models/AlexNet/training_seed_05\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m training_seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAlexNetv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_checkpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_checkpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_seed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_seed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/modelzoo/vision_models.py:324\u001b[0m, in \u001b[0;36mAlexNetv2.__init__\u001b[0;34m(self, model_checkpoint_dir, training_seed)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_checkpoint_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.ckpt_epoch89\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(training_seed)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_checkpoint_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.ckpt_epoch89.meta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_shape_dict \u001b[38;5;241m=\u001b[39m \u001b[43m_get_layer_names_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/modelzoo/vision_models.py:240\u001b[0m, in \u001b[0;36m_get_layer_names_tensors\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Get the shape of each layer\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGraph()\u001b[38;5;241m.\u001b[39mas_default() \u001b[38;5;28;01mas\u001b[39;00m graph:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# Import the model\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     tf\u001b[38;5;241m.\u001b[39mimport_graph_def(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_def\u001b[49m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# Get the shape of each tensor\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     layer_shape_dict \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/python_workspace/lucid-kietzmannlab/src/lucid_kietzmannlab/modelzoo/vision_models.py:346\u001b[0m, in \u001b[0;36mAlexNetv2.graph_def\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m         frozen_graph_def \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    340\u001b[0m             tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mgraph_util\u001b[38;5;241m.\u001b[39mconvert_variables_to_constants(\n\u001b[1;32m    341\u001b[0m                 sess, sess\u001b[38;5;241m.\u001b[39mgraph_def, output_node_names\n\u001b[1;32m    342\u001b[0m             )\n\u001b[1;32m    343\u001b[0m         )\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_def \u001b[38;5;241m=\u001b[39m frozen_graph_def\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_def\u001b[49m \u001b[38;5;241m=\u001b[39m frozen_graph_def\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_def\n",
      "\u001b[0;31mAttributeError\u001b[0m: property 'graph_def' of 'AlexNetv2' object has no setter"
     ]
    }
   ],
   "source": [
    "model_checkpoint_dir=\"/Users/vkapoor/Downloads/models/AlexNet/training_seed_05\"\n",
    "training_seed = 5\n",
    "model = models.AlexNetv2(model_checkpoint_dir=model_checkpoint_dir, training_seed = training_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_shape_dict = model.layer_shape_dict\n",
    "C = lambda neuron: objectives.channel(*neuron)    \n",
    "def visualize(layer_name, channel):\n",
    "    # Check if the layer exists in the shape dictionary\n",
    "    if layer_name in layer_shape_dict:\n",
    "        # Check if the selected channel is within bounds\n",
    "        max_channel = layer_shape_dict[layer_name][-1] - 1\n",
    "        if 0 <= channel <= max_channel:\n",
    "            clear_output(wait=True)\n",
    "            # Render visualization for the selected layer and channel\n",
    "            try:\n",
    "              _ = render.render_vis(model, C((layer_name, channel)), scope = 'alexnet_v2')\n",
    "            except Exception:\n",
    "                print('No gradients for this layer')   \n",
    "\n",
    "def visualize_all():\n",
    "    # Check if the layer exists in the shape dictionary\n",
    "    layer_name = current_dropdown_value({'new': layer_dropdown.value})\n",
    "    print(layer_name)\n",
    "    if layer_name in layer_shape_dict:\n",
    "            # Check if the selected channel is within bounds\n",
    "            try:\n",
    "               image_channel = {} \n",
    "               for channel in tqdm(range(channel_slider.max)):    \n",
    "                  images = render.render_vis(model, C((layer_name, channel)), verbose = False, scope = 'alexnet_v2')\n",
    "                  image_channel[channel] = images \n",
    "            except Exception:\n",
    "                print('No gradients for this layer')    \n",
    "    return image_channel            \n",
    "                              \n",
    "def plot_images(image_channel):\n",
    "    channels = list(image_channel.keys())\n",
    "    for i in range(0, len(channels), 3):\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))  \n",
    "        for j in range(3):\n",
    "            channel_index = i + j\n",
    "            if channel_index < len(channels):\n",
    "                channel = channels[channel_index]\n",
    "                images = image_channel[channel]\n",
    "                try:\n",
    "                    axs[j].imshow(images[0][0,:])  \n",
    "                    axs[j].set_title(f\"Channel {channel}\")\n",
    "                    axs[j].axis('off')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error plotting channel {channel}: {e}\")\n",
    "                    axs[j].axis('off')\n",
    "                    axs[j].text(0.5, 0.5, 'Error', ha='center', va='center')\n",
    "            else:\n",
    "                axs[j].axis('off')  \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "# Create dropdown menu for layer selection\n",
    "layer_dropdown = Dropdown(options=list(layer_shape_dict.keys()), description='Layer:')\n",
    "\n",
    "# Create slider for channel selection\n",
    "channel_slider = IntSlider(min=0, max=0, description='Channel:')\n",
    "        \n",
    "        \n",
    "def update_channel_slider(change):\n",
    "    layer_name = change.new\n",
    "    if layer_name in layer_shape_dict:\n",
    "        \n",
    "        max_channel = layer_shape_dict[layer_name][-1] - 1\n",
    "        channel_slider.max = max_channel\n",
    "        \n",
    "        \n",
    "def current_slider_value(*args):\n",
    "    return channel_slider.value\n",
    "\n",
    "\n",
    "def current_dropdown_value(change):\n",
    "    return change['new']\n",
    "\n",
    "\n",
    "channel_slider.observe(current_slider_value, names='value')\n",
    "layer_dropdown.observe(current_dropdown_value, names='value')\n",
    "        \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dropdown.observe(update_channel_slider, names='value')\n",
    "\n",
    "# Create an interactive visualization\n",
    "interact(visualize, layer_name=layer_dropdown, channel=channel_slider)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channel = visualize_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if image_channel:\n",
    "    plot_images(image_channel)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_shape_dict.values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucidenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
