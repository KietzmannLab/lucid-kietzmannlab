
"""
Input arguments
sys.argv[1]: model_folder_file_path excluding filename ending
sys.argv[2]: output_size
sys.argv[3]: 1 - model.keep_prob
sys.argv[4]: training_seed
sys.argv[5]: DISTANCE_MEASURE
sys.argv[6]: save_activations
sys.argv[7]: training_set (ecoset vs. ILSVRC2012)
sys.argv[8]: layer
sys.argv[9]: compute_RDMs_bool
"""


import os
import sys
import json
import glob
import time
import copy

import numpy as np
import tensorflow as tf
from scipy.io import loadmat, savemat
from PIL import Image
from scipy.spatial.distance import pdist, squareform
from scipy.stats import rankdata
import re



CKPT_PATH = sys.argv[1] # CHANGE 06
output_size = sys.argv[2]
dropout_rate = 0.5
random_seed = sys.argv[3]
DISTANCE_MEASURE = sys.argv[4]
IMAGE_DIR = sys.argv[5]
training_set = sys.argv[6]
layer = int(sys.argv[7])
compute_RDMs_bool = int(sys.argv[8])

np.random.seed(int(sys.argv[3]))
# sets the graph based random seed
RANDOM_SEED_GRAPH = int(sys.argv[3])


argv_1 = CKPT_PATH
argv_1_list = argv_1.split(os.sep)
ckpt_name = argv_1_list[-1]
save_name = 'training_seed_{0}'.format(random_seed.zfill(2)) #argv_1_list[len(argv_1_list) - 2]
# dropout type
DROPOUT_TYPE = 'bernoulli'

# path to the specific checkpoint file
ckpt_path = CKPT_PATH

# path to the model that we feed the images to
model_folder = "/data/models/AlexNet/models_AlexNet_{}/b_vNet_alexnet.py".format(training_set)

sys.path.append('/data/models/AlexNet/')


# load model: vNet ecoset vs. vNet ILSVRC2012 (565 vs. 1000 units in final layer)
if training_set == "ecoset":
    from models_AlexNet_ecoset.b_net_alexnet import AlexNet
elif training_set == "ILSVRC2012":
    from models_AlexNet_ILSVRC2012.b_net_alexnet import AlexNet
os.environ['CUDA_VISIBLE_DEVICES'] = '1'

# results_dir: every output from the run of a codeocean capsule is saved in the folder "results" in the main folder
results_dir = '../results'
save_dir = os.path.join(results_dir, save_name)

# folder containing all RDL92/61 categories
exp_stimuli_path =  IMAGE_DIR # image_input_only_niko_92, kamitani


#%% model specs
model_type = 'b_net_alexnet'
scale_blt = [1., 1., 1.]
scale_parameters = None
n_layers = 7
n_timesteps = 1
layer_features = (64, 192, 384, 384, 256, 4096, 4096)
k_size = (11, 5, 3, 3, 3, 3, None, None)
pool_size = (None, 3, 3, None, 3, None, None)
output_size = int(sys.argv[2]) #565 vs 1000
save_network_activations = True
rdm_times = 0


#%% load stimuli

def load_images(exp_stimuli_path):
    '''
    Loads images resize to 224x224

    Returns:
        image_list:         stack of loaded images in 224x224 resolution
        image_name_list:    list of names of loaded files for saving of mat files

    '''
    # get all files in the directory and sort them
    dir_files = sorted(glob.glob(os.path.join(exp_stimuli_path, '*')))

    # initialise the list to store images
    images_list = []

    # keep track of ignored files in folder
    ignored_files = 0

    image_name_list = []
    for fname in dir_files:

        # get file name for later saving of activations
        img_file_name = os.path.splitext(os.path.basename(fname))[0]
        image_name_list.append(img_file_name)

        # load the image checking if it is a valid file type
        try:
            img_i = Image.open(fname)

        except IOError:
            print('not a recognised image file, ignoring: {0}'.format(fname))
            ignored_files += 1
            continue

        # HPC HPC HPC crop center part of image
        width, height = img_i.size
        min_dim = min([width, height])
        y_crop = min_dim / width
        x_crop = min_dim / height
        y0 = (1 - y_crop) / 2
        x0 = (1 - x_crop) / 2
        y1 = 1 - y0
        x1 = 1 - x0
        crop_box = [y0, x0, y1, x1]
        img_i_array_cropped = img_i.crop((round(crop_box[0]*width),
                                  round(crop_box[1]*height),
                                  round(crop_box[2]*width),
                                  round(crop_box[3]*height)))

        # HPC HPC HPC resize image to fit input size of DNN
        img_i_array_resized_tmp = img_i_array_cropped.resize((224, 224), Image.BILINEAR)
        img_i_array_resized = np.asarray(img_i_array_resized_tmp) # HPC HPC HPC
        images_list.append(img_i_array_resized)


    return np.array(images_list), image_name_list



#%% extract activations

def build_graph(model_type,
                loaded_images,
                n_layers=7,
                n_timesteps=1,
                layer_features = ( 64, 192, 384, 384, 256, 4096, 4096),
                output_size = 565,
                k_size =    (  11,  5,  3,    3,    3,    3,  5,  1),
                pool_size = (None,  3,  3, None, None, None, None, None)):


    '''
    Builds the graph for the model to be tested. Includes image centring

    Args:
        model_type:     the type of the model to be tested of: b, bt, bl, blt
        n_layers:       the number of layers to build into the graph
        layer_features: the number of features to build into the graph

    Returns:
        graph:    the computational graph for the model
        model:    the model object
    '''

    graph = tf.Graph()
    with graph.as_default():

        if RANDOM_SEED_GRAPH is not None:
            # set the graph based random seed
            tf.set_random_seed(RANDOM_SEED_GRAPH)

        #model_device = '/gpu:0'
        #data_format = 'NCHW'
        #loaded_images = np.transpose(loaded_images, (0, 3, 1, 2))
        model_device = '/cpu:0'
        data_format = 'NHWC'


        # define the images placeholder
        img_ph = tf.placeholder(tf.uint8, np.shape(loaded_images)[1:], 'images_ph')



        # rescale the image
        image_float32 = tf.image.convert_image_dtype(img_ph, tf.float32)
        image_rescaled = (image_float32 - 0.5) * 2
        images_tensor = image_rescaled

        image_tiled = tf.tile(tf.expand_dims(image_rescaled, 0), [1, 1, 1, 1])

        model = AlexNet(
            image_tiled, var_device=model_device, default_timesteps=n_timesteps,
            data_format=data_format, random_seed=RANDOM_SEED_GRAPH)

        model.output_size = output_size
        model.dropout_type = DROPOUT_TYPE
        model.net_mode = 'test'
        model.is_training = False
        model.build_model()

    return graph, images_tensor, model, img_ph




def extract_and_save_activations(
    loaded_images,
    image_name_list,
    save_path_activations,
    graph,
    images_tensor,
    model,
    ckpt_path,
    exp_stimuli_cat_limit,
    layer,
    img_ph):
    '''
    Extract the responses of the network to images

    Args:
        images:       an array of images of shape [n_images, width, height, channels]
        graph:        the graph object for the network returned from build_graph
        image_tensor: placeholder corresponding to the image tensor
        model:        the model object for the network returned from build_graph
        ckpt_path:    the path to the checkpoint file to restore from
        cat:                           category for checking amount of images per category

    Returns:
        act_list:    a list containing the activations for each layer to all images in the following format [time, image, channels, height, width]

    '''

    n_images = loaded_images.shape[0]
    if n_images != exp_stimuli_cat_limit:
        print('saving_2 (shape) ############### this cat: ' + cat)
        print(str(n_images) + ' does not equal ' + str(exp_stimuli_cat_limit))
        os._exit()

    # set-up config object for session
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True

    with tf.Session(graph=graph, config=config) as sess:

        activations = model.activations
        activations_readout_before_softmax = model.readout # batch_size x class
        activations_readout_after_softmax = tf.nn.softmax(activations_readout_before_softmax)

        # restore the network
        saver = tf.train.Saver()
        saver.restore(sess, ckpt_path)

        # progress bar
        print('extracting activations...')

        for image_i, image in enumerate(loaded_images):
            start = time.time()
            # transpose and reshape image
            input_image = image # CPU-mode: don't transpose or change shape
            # set random seeds
            np.random.seed(int(sys.argv[3]))
            tf.set_random_seed(int(sys.argv[3]))


            ops_to_run = [activations, activations_readout_before_softmax, activations_readout_after_softmax]

            batch_act, batch_act_readout_before_softmax, batch_act_readout_after_softmax = sess.run(ops_to_run, feed_dict={img_ph: input_image})

            # save activations
            activation_dict = {}
            for layer_i in [layer]: # CHANGE 15
                if layer_i == 0:
                    activation_dict['layer_{0}'.format(str(layer_i + 1).zfill(3))] = np.squeeze(batch_act[0][layer_i])
                    print('layer 0')
                    print(activation_dict['layer_{0}'.format(str(layer_i + 1).zfill(3))].shape)
                    savemat(os.path.join(save_path_activations, 'layer_{0}_img_idx_{1}_image_id_{2}_random_seed_{3}_training_set_{4}.mat'.format(str((layer_i + 1)).zfill(3), str(image_i + 1).zfill(4), image_name_list[image_i], str(int(sys.argv[3])).zfill(2), training_set)), activation_dict)
                    activation_dict = {}

                # layer 2-5 - all conv layers, but the first
                elif layer_i < 5:
                    activation_dict['layer_{0}'.format(str(layer_i + 1).zfill(3))] = np.squeeze(batch_act[0][layer_i])
                    print('layer 2-5')
                    print(activation_dict['layer_{0}'.format(str(layer_i + 1).zfill(3))].shape)
                    savemat(os.path.join(save_path_activations, 'layer_{0}_img_idx_{1}_image_id_{2}_random_seed_{3}_training_set_{4}.mat'.format(str((layer_i + 1)).zfill(3), str(image_i + 1).zfill(4), image_name_list[image_i], str(int(sys.argv[3])).zfill(2), training_set)), activation_dict)
                    activation_dict = {}

                # the fully connected layers
                elif layer_i == 5 or layer_i == 6:
                    activation_dict['layer_{0}'.format(str(layer_i + 1).zfill(3))] = np.squeeze(batch_act[0][layer_i])
                    print('layer 6-7')
                    print(activation_dict['layer_{0}'.format(str(layer_i + 1).zfill(3))].shape)
                    savemat(os.path.join(save_path_activations, 'layer_{0}_img_idx_{1}_image_id_{2}_random_seed_{3}_training_set_{4}.mat'.format(str((layer_i + 1)).zfill(3), str(image_i + 1).zfill(4), image_name_list[image_i], str(int(sys.argv[3])).zfill(2), training_set)), activation_dict)
                    activation_dict = {}

                # readout before softmax
                elif layer_i == model.n_layers:
                    activation_dict['layer_{0}'.format(str(layer_i + 1).zfill(3))] = np.squeeze(batch_act_readout_before_softmax)
                    print('readout before softmax')
                    print(len(activation_dict['layer_{0}'.format(str(layer_i + 1).zfill(3))]))
                    savemat(os.path.join(save_path_activations, 'layer_{0}_img_idx_{1}_image_id_{2}_random_seed_{3}_training_set_{4}.mat'.format(str((layer_i + 1)).zfill(3), str(image_i + 1).zfill(4), image_name_list[image_i], str(int(sys.argv[3])).zfill(2), training_set)), activation_dict)
                    activation_dict = {}

                # readout after softmax
                elif layer_i == model.n_layers + 1:
                    activation_dict['layer_{0}'.format(str(layer_i + 1).zfill(3))] = np.squeeze(batch_act_readout_after_softmax)
                    print('readout after softmax')
                    print(len(activation_dict['layer_{0}'.format(str(layer_i + 1).zfill(3))]))
                    savemat(os.path.join(save_path_activations, 'layer_{0}_img_idx_{1}_image_id_{2}_random_seed_{3}_training_set_{4}.mat'.format(str((layer_i + 1)).zfill(3), str(image_i + 1).zfill(4), image_name_list[image_i], str(int(sys.argv[3])).zfill(2), training_set)), activation_dict)
                    activation_dict = {}
            end = time.time()


#%% compute RDMs
def compute_RDMs(loaded_images,
        image_name_list,
        save_path_activations,
        graph,
        images_tensor,
        model,
        ckpt_path,
        exp_stimuli_cat_limit,
        layer):

    save_name = 'training_seed_{0}'.format(random_seed.zfill(2))
    cwd = os.getcwd()
    cwd_split = os.path.split(cwd)
    cwd_parent = cwd_split[0]
    results_dir = os.path.join(cwd_parent, 'results')
    save_dir = os.path.join(results_dir, save_name)


    # get layer-specific file list
    IMAGE_DIR_split = os.path.split(IMAGE_DIR)
    IMAGE_DIR_split_2 = os.path.split(IMAGE_DIR_split[0])
    save_path_activations = os.path.join(save_dir, IMAGE_DIR_split_2[-1], 'activations')
    layer_activations_files = sorted(glob.glob(os.path.join(save_path_activations, 'layer_{0}*{1}*'.format(str(int(layer) + 1).zfill(3), training_set))))

    # load files
    layer_activations_tmp = []
    for img in layer_activations_files:
        tmp = loadmat(img)
        tmp_2 = np.ndarray.flatten(tmp['layer_{0}'.format(str(int(layer) + 1).zfill(3))])
        layer_activations_tmp.append(tmp_2)
    layer_activations = np.vstack(layer_activations_tmp)

    # compute RDM
    RDM = pdist(layer_activations, DISTANCE_MEASURE)

    # create RDMs save dir
    save_path_RDMs = os.path.join(save_dir, IMAGE_DIR_split_2[-1], 'RDMs')
    if not os.path.isdir(save_path_RDMs):
        os.mkdir(save_path_RDMs)

    # save RDM in .mat (matlab) and .npy (python numpy) format
    RDM_dict = {}
    RDM_dict['RDM'] = RDM
    savemat(os.path.join(save_path_RDMs, '{0}_{1}_layer_{2}_dst_measure_{3}.mat'.format(save_name, cwd_split[1], str(int(layer) + 1).zfill(3), DISTANCE_MEASURE)), RDM_dict)
    np.save(os.path.join(save_path_RDMs, '{0}_{1}_layer_{2}_dst_measure_{3}'.format(save_name, cwd_split[1], str(int(layer) + 1).zfill(3), DISTANCE_MEASURE)), RDM)



#%% run script

# create activation save path parent folders
if not os.path.isdir(os.path.join(results_dir)):
    os.mkdir(os.path.join(results_dir))
if not os.path.isdir(os.path.join(save_dir)):
    os.mkdir(os.path.join(save_dir))

# create save path structure for each category
IMAGE_DIR_split = os.path.split(IMAGE_DIR)
IMAGE_DIR_split_2 = os.path.split(IMAGE_DIR_split[0])
save_path_activations_tmp = os.path.join(save_dir, IMAGE_DIR_split_2[-1])
if not os.path.isdir(save_path_activations_tmp):
    os.mkdir(save_path_activations_tmp)
save_path_activations = os.path.join(save_dir, IMAGE_DIR_split_2[-1], 'activations')
if not os.path.isdir(save_path_activations):
    os.mkdir(save_path_activations)


# load experimental stimuli
tmp_cat_n_imgs = os.listdir(os.path.join(exp_stimuli_path))
exp_stimuli_cat_limit = len(tmp_cat_n_imgs)


loaded_images, image_name_list = load_images(os.path.join(exp_stimuli_path))


# build the tensor graph
graph, images_tensor, model, img_ph = build_graph(model_type,
                                      loaded_images,
                                      n_layers=n_layers,
                                      n_timesteps=n_timesteps,
                                      layer_features=layer_features,
                                      output_size=output_size)

# extract activations
extract_and_save_activations(
                        loaded_images,
                        image_name_list,
                        save_path_activations,
                        graph,
                        images_tensor,
                        model,
                        ckpt_path,
                        exp_stimuli_cat_limit,
                        layer,
                        img_ph)

if compute_RDMs_bool:
    compute_RDMs(
        loaded_images,
        image_name_list,
        save_path_activations,
        graph,
        images_tensor,
        model,
        ckpt_path,
        exp_stimuli_cat_limit,
        layer)





# save analysis parameters
analysis_params = {
    'model_folder': model_folder,
    'ckpt_name': ckpt_name,
    'save_dir': save_name,
    'model_type': model_type,
    'n_layers': n_layers,
    'layer_features': layer_features
}

with open(os.path.join(results_dir, save_dir, 'analysis_params.json'), 'w') as fp:
    json.dump(analysis_params, fp)
