{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "import lucid_kietzmannlab.modelzoo.vision_models as models\n",
    "\n",
    "\n",
    "model_checkpoint_dir = \"/Users/vkapoor/Downloads/training_seed_05\"\n",
    "model_checkpoint = \"model.ckpt_epoch89\"\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    model = models.AlexNetEcoset(model_checkpoint_dir = model_checkpoint_dir, model_checkpoint = model_checkpoint)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import tf_slim as slim\n",
    "\n",
    "def get_weights():\n",
    "  return [\n",
    "    v for v in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    if v.name.endswith('weights:0')\n",
    "    ]\n",
    "  \n",
    "def alexnet_v2(inputs,\n",
    "               num_classes=1000,\n",
    "               is_training=True,\n",
    "               dropout_keep_prob=0.5,\n",
    "               spatial_squeeze=True,\n",
    "               scope='alexnet_v2',\n",
    "               global_pool=False,\n",
    "               reuse_variables=True,\n",
    "               data_format='NHWC'\n",
    "               ):\n",
    "  \"\"\"AlexNet version 2.\n",
    "  Described in: http://arxiv.org/pdf/1404.5997v2.pdf\n",
    "  Parameters from:\n",
    "  github.com/akrizhevsky/cuda-convnet2/blob/master/layers/\n",
    "  layers-imagenet-1gpu.cfg\n",
    "  Note: All the fully_connected layers have been transformed to conv2d layers.\n",
    "        To use in classification mode, resize input to 224x224 or set\n",
    "        global_pool=True. To use in fully convolutional mode, set\n",
    "        spatial_squeeze to false.\n",
    "        The LRN layers have been removed and change the initializers from\n",
    "        random_normal_initializer to xavier_initializer.\n",
    "  Args:\n",
    "    inputs: a tensor of size [batch_size, height, width, channels].\n",
    "    num_classes: the number of predicted classes. If 0 or None, the logits layer\n",
    "    is omitted and the input features to the logits layer are returned instead.\n",
    "    is_training: whether or not the model is being trained.\n",
    "    dropout_keep_prob: the probability that activations are kept in the dropout\n",
    "      layers during training.\n",
    "    spatial_squeeze: whether or not should squeeze the spatial dimensions of the\n",
    "      logits. Useful to remove unnecessary dimensions for classification.\n",
    "    scope: Optional scope for the variables.\n",
    "    global_pool: Optional boolean flag. If True, the input to the classification\n",
    "      layer is avgpooled to size 1x1, for any input size. (This is not part\n",
    "      of the original AlexNet.)\n",
    "  Returns:\n",
    "    net: the output of the logits layer (if num_classes is a non-zero integer),\n",
    "      or the non-dropped-out input to the logits layer (if num_classes is 0\n",
    "      or None).\n",
    "    end_points: a dict of tensors with intermediate activations.\n",
    "  \"\"\"\n",
    "  act = []\n",
    "  with tf.variable_scope(scope, 'alexnet_v2', [inputs], reuse=reuse_variables) as sc:\n",
    "    end_points_collection = sc.original_name_scope + '_end_points'\n",
    "    # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                        outputs_collections=[end_points_collection], data_format=data_format):\n",
    "      net = slim.conv2d(inputs, 64, [11, 11], 4, padding='VALID',\n",
    "                        scope='conv1')\n",
    "      act.append(net)\n",
    "      net = slim.max_pool2d(net, [3, 3], 2, scope='pool1')\n",
    "      net = slim.conv2d(net, 192, [5, 5], scope='conv2')\n",
    "      act.append(net)\n",
    "      net = slim.max_pool2d(net, [3, 3], 2, scope='pool2')\n",
    "      net = slim.conv2d(net, 384, [3, 3], scope='conv3')\n",
    "      act.append(net)\n",
    "      net = slim.conv2d(net, 384, [3, 3], scope='conv4')\n",
    "      act.append(net)\n",
    "      net = slim.conv2d(net, 256, [3, 3], scope='conv5')\n",
    "      act.append(net)\n",
    "      net = slim.max_pool2d(net, [3, 3], 2, scope='pool5')\n",
    "\n",
    "      # Use conv2d instead of fully_connected layers.\n",
    "      with slim.arg_scope(\n",
    "          [slim.conv2d],\n",
    "          weights_initializer=trunc_normal(0.005),\n",
    "          biases_initializer=tf.constant_initializer(0.1)):\n",
    "        net = slim.conv2d(net, 4096, [5, 5], padding='VALID',\n",
    "                          scope='fc6')\n",
    "        net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                           scope='dropout6')\n",
    "        act.append(net)\n",
    "        net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "        act.append(net)\n",
    "        # Convert end_points_collection into a end_point dict.\n",
    "        end_points = slim.utils.convert_collection_to_dict(\n",
    "            end_points_collection)\n",
    "        if global_pool:\n",
    "          net = tf.reduce_mean(\n",
    "              input_tensor=net, axis=[1, 2], keepdims=True, name='global_pool')\n",
    "          end_points['global_pool'] = net\n",
    "        if num_classes:\n",
    "          net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                             scope='dropout7')\n",
    "          net = slim.conv2d(\n",
    "              net,\n",
    "              num_classes, [1, 1],\n",
    "              activation_fn=None,\n",
    "              normalizer_fn=None,\n",
    "              biases_initializer=tf.zeros_initializer(),\n",
    "              scope='fc8')\n",
    "          if spatial_squeeze:\n",
    "            squeeze_dims = [2, 3] if data_format == 'NCHW' else [1, 2]\n",
    "            net = tf.squeeze(net, squeeze_dims, name='fc8/squeezed')\n",
    "          readout = net\n",
    "          end_points[sc.name + '/fc8'] = net\n",
    "      return readout, act, get_weights()\n",
    "alexnet_v2.default_image_size = 224\n",
    "\n",
    "\n",
    "trunc_normal = lambda stddev: tf.truncated_normal_initializer(\n",
    "    0.0, stddev)\n",
    "\n",
    "\n",
    "def alexnet_v2_arg_scope(weight_decay=0.0005):\n",
    "  with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                      activation_fn=tf.nn.relu,\n",
    "                      biases_initializer=tf.constant_initializer(0.1),\n",
    "                      weights_regularizer=slim.l2_regularizer(weight_decay)):\n",
    "    with slim.arg_scope([slim.conv2d], padding='SAME'):\n",
    "      with slim.arg_scope([slim.max_pool2d], padding='VALID') as arg_sc:\n",
    "        return arg_sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucidenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
