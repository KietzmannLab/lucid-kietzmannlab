{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vkapoor/miniconda3/envs/lucidenv/lib/python3.12/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2024-06-07 16:55:36.455887: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/vkapoor/Downloads/training_seed_05/model.ckpt_epoch89\n",
      "Model loaded from: /Users/vkapoor/Downloads/training_seed_05/model.ckpt_epoch89\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "import lucid_kietzmannlab.modelzoo.vision_models as models\n",
    "\n",
    "\n",
    "model_checkpoint_dir = \"/Users/vkapoor/Downloads/training_seed_05\"\n",
    "model_checkpoint = \"model.ckpt_epoch89\"\n",
    "model, sess, logits, activations, weights, layer_shape_dict = models.load_ecoset_model_seeds(model_checkpoint_dir, model_checkpoint)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Placeholder, Shape: (None, 224, 224, 3)\n",
      "Layer: alexnet_v2/conv1/weights/Initializer/random_uniform/shape, Shape: (4,)\n",
      "Layer: alexnet_v2/conv1/weights/Initializer/random_uniform/RandomUniform, Shape: (11, 11, 3, 64)\n",
      "Layer: alexnet_v2/conv1/weights/Initializer/random_uniform/mul, Shape: (11, 11, 3, 64)\n",
      "Layer: alexnet_v2/conv1/weights/Initializer/random_uniform, Shape: (11, 11, 3, 64)\n",
      "Layer: alexnet_v2/conv1/weights/Assign, Shape: None\n",
      "Layer: alexnet_v2/conv1/weights/Read/ReadVariableOp, Shape: (11, 11, 3, 64)\n",
      "Layer: alexnet_v2/conv1/kernel/Regularizer/l2_regularizer/L2Loss/ReadVariableOp, Shape: (11, 11, 3, 64)\n",
      "Layer: alexnet_v2/conv1/biases/Initializer/Const, Shape: (64,)\n",
      "Layer: alexnet_v2/conv1/biases/Assign, Shape: None\n",
      "Layer: alexnet_v2/conv1/biases/Read/ReadVariableOp, Shape: (64,)\n",
      "Layer: alexnet_v2/conv1/Conv2D/ReadVariableOp, Shape: (11, 11, 3, 64)\n",
      "Layer: alexnet_v2/conv1/Conv2D, Shape: (None, 54, 54, 64)\n",
      "Layer: alexnet_v2/conv1/BiasAdd/ReadVariableOp, Shape: (64,)\n",
      "Layer: alexnet_v2/conv1/BiasAdd, Shape: (None, 54, 54, 64)\n",
      "Layer: alexnet_v2/conv1/Relu, Shape: (None, 54, 54, 64)\n",
      "Layer: alexnet_v2/pool1/MaxPool, Shape: (None, 26, 26, 64)\n",
      "Layer: alexnet_v2/conv2/weights/Initializer/random_uniform/shape, Shape: (4,)\n",
      "Layer: alexnet_v2/conv2/weights/Initializer/random_uniform/RandomUniform, Shape: (5, 5, 64, 192)\n",
      "Layer: alexnet_v2/conv2/weights/Initializer/random_uniform/mul, Shape: (5, 5, 64, 192)\n",
      "Layer: alexnet_v2/conv2/weights/Initializer/random_uniform, Shape: (5, 5, 64, 192)\n",
      "Layer: alexnet_v2/conv2/weights/Assign, Shape: None\n",
      "Layer: alexnet_v2/conv2/weights/Read/ReadVariableOp, Shape: (5, 5, 64, 192)\n",
      "Layer: alexnet_v2/conv2/kernel/Regularizer/l2_regularizer/L2Loss/ReadVariableOp, Shape: (5, 5, 64, 192)\n",
      "Layer: alexnet_v2/conv2/biases/Initializer/Const, Shape: (192,)\n",
      "Layer: alexnet_v2/conv2/biases/Assign, Shape: None\n",
      "Layer: alexnet_v2/conv2/biases/Read/ReadVariableOp, Shape: (192,)\n",
      "Layer: alexnet_v2/conv2/Conv2D/ReadVariableOp, Shape: (5, 5, 64, 192)\n",
      "Layer: alexnet_v2/conv2/Conv2D, Shape: (None, 26, 26, 192)\n",
      "Layer: alexnet_v2/conv2/BiasAdd/ReadVariableOp, Shape: (192,)\n",
      "Layer: alexnet_v2/conv2/BiasAdd, Shape: (None, 26, 26, 192)\n",
      "Layer: alexnet_v2/conv2/Relu, Shape: (None, 26, 26, 192)\n",
      "Layer: alexnet_v2/pool2/MaxPool, Shape: (None, 12, 12, 192)\n",
      "Layer: alexnet_v2/conv3/weights/Initializer/random_uniform/shape, Shape: (4,)\n",
      "Layer: alexnet_v2/conv3/weights/Initializer/random_uniform/RandomUniform, Shape: (3, 3, 192, 384)\n",
      "Layer: alexnet_v2/conv3/weights/Initializer/random_uniform/mul, Shape: (3, 3, 192, 384)\n",
      "Layer: alexnet_v2/conv3/weights/Initializer/random_uniform, Shape: (3, 3, 192, 384)\n",
      "Layer: alexnet_v2/conv3/weights/Assign, Shape: None\n",
      "Layer: alexnet_v2/conv3/weights/Read/ReadVariableOp, Shape: (3, 3, 192, 384)\n",
      "Layer: alexnet_v2/conv3/kernel/Regularizer/l2_regularizer/L2Loss/ReadVariableOp, Shape: (3, 3, 192, 384)\n",
      "Layer: alexnet_v2/conv3/biases/Initializer/Const, Shape: (384,)\n",
      "Layer: alexnet_v2/conv3/biases/Assign, Shape: None\n",
      "Layer: alexnet_v2/conv3/biases/Read/ReadVariableOp, Shape: (384,)\n",
      "Layer: alexnet_v2/conv3/Conv2D/ReadVariableOp, Shape: (3, 3, 192, 384)\n",
      "Layer: alexnet_v2/conv3/Conv2D, Shape: (None, 12, 12, 384)\n",
      "Layer: alexnet_v2/conv3/BiasAdd/ReadVariableOp, Shape: (384,)\n",
      "Layer: alexnet_v2/conv3/BiasAdd, Shape: (None, 12, 12, 384)\n",
      "Layer: alexnet_v2/conv3/Relu, Shape: (None, 12, 12, 384)\n",
      "Layer: alexnet_v2/conv4/weights/Initializer/random_uniform/shape, Shape: (4,)\n",
      "Layer: alexnet_v2/conv4/weights/Initializer/random_uniform/RandomUniform, Shape: (3, 3, 384, 384)\n",
      "Layer: alexnet_v2/conv4/weights/Initializer/random_uniform/mul, Shape: (3, 3, 384, 384)\n",
      "Layer: alexnet_v2/conv4/weights/Initializer/random_uniform, Shape: (3, 3, 384, 384)\n",
      "Layer: alexnet_v2/conv4/weights/Assign, Shape: None\n",
      "Layer: alexnet_v2/conv4/weights/Read/ReadVariableOp, Shape: (3, 3, 384, 384)\n",
      "Layer: alexnet_v2/conv4/kernel/Regularizer/l2_regularizer/L2Loss/ReadVariableOp, Shape: (3, 3, 384, 384)\n",
      "Layer: alexnet_v2/conv4/biases/Initializer/Const, Shape: (384,)\n",
      "Layer: alexnet_v2/conv4/biases/Assign, Shape: None\n",
      "Layer: alexnet_v2/conv4/biases/Read/ReadVariableOp, Shape: (384,)\n",
      "Layer: alexnet_v2/conv4/Conv2D/ReadVariableOp, Shape: (3, 3, 384, 384)\n",
      "Layer: alexnet_v2/conv4/Conv2D, Shape: (None, 12, 12, 384)\n",
      "Layer: alexnet_v2/conv4/BiasAdd/ReadVariableOp, Shape: (384,)\n",
      "Layer: alexnet_v2/conv4/BiasAdd, Shape: (None, 12, 12, 384)\n",
      "Layer: alexnet_v2/conv4/Relu, Shape: (None, 12, 12, 384)\n",
      "Layer: alexnet_v2/conv5/weights/Initializer/random_uniform/shape, Shape: (4,)\n",
      "Layer: alexnet_v2/conv5/weights/Initializer/random_uniform/RandomUniform, Shape: (3, 3, 384, 256)\n",
      "Layer: alexnet_v2/conv5/weights/Initializer/random_uniform/mul, Shape: (3, 3, 384, 256)\n",
      "Layer: alexnet_v2/conv5/weights/Initializer/random_uniform, Shape: (3, 3, 384, 256)\n",
      "Layer: alexnet_v2/conv5/weights/Assign, Shape: None\n",
      "Layer: alexnet_v2/conv5/weights/Read/ReadVariableOp, Shape: (3, 3, 384, 256)\n",
      "Layer: alexnet_v2/conv5/kernel/Regularizer/l2_regularizer/L2Loss/ReadVariableOp, Shape: (3, 3, 384, 256)\n",
      "Layer: alexnet_v2/conv5/biases/Initializer/Const, Shape: (256,)\n",
      "Layer: alexnet_v2/conv5/biases/Assign, Shape: None\n",
      "Layer: alexnet_v2/conv5/biases/Read/ReadVariableOp, Shape: (256,)\n",
      "Layer: alexnet_v2/conv5/Conv2D/ReadVariableOp, Shape: (3, 3, 384, 256)\n",
      "Layer: alexnet_v2/conv5/Conv2D, Shape: (None, 12, 12, 256)\n",
      "Layer: alexnet_v2/conv5/BiasAdd/ReadVariableOp, Shape: (256,)\n",
      "Layer: alexnet_v2/conv5/BiasAdd, Shape: (None, 12, 12, 256)\n",
      "Layer: alexnet_v2/conv5/Relu, Shape: (None, 12, 12, 256)\n",
      "Layer: alexnet_v2/pool5/MaxPool, Shape: (None, 5, 5, 256)\n",
      "Layer: alexnet_v2/fc6/weights/Initializer/truncated_normal/shape, Shape: (4,)\n",
      "Layer: alexnet_v2/fc6/weights/Initializer/truncated_normal/TruncatedNormal, Shape: (5, 5, 256, 4096)\n",
      "Layer: alexnet_v2/fc6/weights/Initializer/truncated_normal/mul, Shape: (5, 5, 256, 4096)\n",
      "Layer: alexnet_v2/fc6/weights/Initializer/truncated_normal, Shape: (5, 5, 256, 4096)\n",
      "Layer: alexnet_v2/fc6/weights/Assign, Shape: None\n",
      "Layer: alexnet_v2/fc6/weights/Read/ReadVariableOp, Shape: (5, 5, 256, 4096)\n",
      "Layer: alexnet_v2/fc6/kernel/Regularizer/l2_regularizer/L2Loss/ReadVariableOp, Shape: (5, 5, 256, 4096)\n",
      "Layer: alexnet_v2/fc6/biases/Initializer/Const, Shape: (4096,)\n",
      "Layer: alexnet_v2/fc6/biases/Assign, Shape: None\n",
      "Layer: alexnet_v2/fc6/biases/Read/ReadVariableOp, Shape: (4096,)\n",
      "Layer: alexnet_v2/fc6/Conv2D/ReadVariableOp, Shape: (5, 5, 256, 4096)\n",
      "Layer: alexnet_v2/fc6/Conv2D, Shape: (None, 1, 1, 4096)\n",
      "Layer: alexnet_v2/fc6/BiasAdd/ReadVariableOp, Shape: (4096,)\n",
      "Layer: alexnet_v2/fc6/BiasAdd, Shape: (None, 1, 1, 4096)\n",
      "Layer: alexnet_v2/fc6/Relu, Shape: (None, 1, 1, 4096)\n",
      "Layer: alexnet_v2/dropout6/Identity, Shape: (None, 1, 1, 4096)\n",
      "Layer: alexnet_v2/fc7/weights/Initializer/truncated_normal/shape, Shape: (4,)\n",
      "Layer: alexnet_v2/fc7/weights/Initializer/truncated_normal/TruncatedNormal, Shape: (1, 1, 4096, 4096)\n",
      "Layer: alexnet_v2/fc7/weights/Initializer/truncated_normal/mul, Shape: (1, 1, 4096, 4096)\n",
      "Layer: alexnet_v2/fc7/weights/Initializer/truncated_normal, Shape: (1, 1, 4096, 4096)\n",
      "Layer: alexnet_v2/fc7/weights/Assign, Shape: None\n",
      "Layer: alexnet_v2/fc7/weights/Read/ReadVariableOp, Shape: (1, 1, 4096, 4096)\n",
      "Layer: alexnet_v2/fc7/kernel/Regularizer/l2_regularizer/L2Loss/ReadVariableOp, Shape: (1, 1, 4096, 4096)\n",
      "Layer: alexnet_v2/fc7/biases/Initializer/Const, Shape: (4096,)\n",
      "Layer: alexnet_v2/fc7/biases/Assign, Shape: None\n",
      "Layer: alexnet_v2/fc7/biases/Read/ReadVariableOp, Shape: (4096,)\n",
      "Layer: alexnet_v2/fc7/Conv2D/ReadVariableOp, Shape: (1, 1, 4096, 4096)\n",
      "Layer: alexnet_v2/fc7/Conv2D, Shape: (None, 1, 1, 4096)\n",
      "Layer: alexnet_v2/fc7/BiasAdd/ReadVariableOp, Shape: (4096,)\n",
      "Layer: alexnet_v2/fc7/BiasAdd, Shape: (None, 1, 1, 4096)\n",
      "Layer: alexnet_v2/fc7/Relu, Shape: (None, 1, 1, 4096)\n",
      "Layer: alexnet_v2/dropout7/Identity, Shape: (None, 1, 1, 4096)\n",
      "Layer: alexnet_v2/fc8/weights/Initializer/truncated_normal/shape, Shape: (4,)\n",
      "Layer: alexnet_v2/fc8/weights/Initializer/truncated_normal/TruncatedNormal, Shape: (1, 1, 4096, 1000)\n",
      "Layer: alexnet_v2/fc8/weights/Initializer/truncated_normal/mul, Shape: (1, 1, 4096, 1000)\n",
      "Layer: alexnet_v2/fc8/weights/Initializer/truncated_normal, Shape: (1, 1, 4096, 1000)\n",
      "Layer: alexnet_v2/fc8/weights/Assign, Shape: None\n",
      "Layer: alexnet_v2/fc8/weights/Read/ReadVariableOp, Shape: (1, 1, 4096, 1000)\n",
      "Layer: alexnet_v2/fc8/kernel/Regularizer/l2_regularizer/L2Loss/ReadVariableOp, Shape: (1, 1, 4096, 1000)\n",
      "Layer: alexnet_v2/fc8/biases/Initializer/zeros/shape_as_tensor, Shape: (1,)\n",
      "Layer: alexnet_v2/fc8/biases/Initializer/zeros, Shape: (1000,)\n",
      "Layer: alexnet_v2/fc8/biases/Assign, Shape: None\n",
      "Layer: alexnet_v2/fc8/biases/Read/ReadVariableOp, Shape: (1000,)\n",
      "Layer: alexnet_v2/fc8/Conv2D/ReadVariableOp, Shape: (1, 1, 4096, 1000)\n",
      "Layer: alexnet_v2/fc8/Conv2D, Shape: (None, 1, 1, 1000)\n",
      "Layer: alexnet_v2/fc8/BiasAdd/ReadVariableOp, Shape: (1000,)\n",
      "Layer: alexnet_v2/fc8/BiasAdd, Shape: (None, 1, 1, 1000)\n",
      "Layer: alexnet_v2/fc8/squeezed, Shape: (None, 1000)\n",
      "Layer: init, Shape: None\n",
      "Layer: save/SaveV2/tensor_names, Shape: (16,)\n",
      "Layer: save/SaveV2/shape_and_slices, Shape: (16,)\n",
      "Layer: save/SaveV2, Shape: None\n",
      "Layer: save/RestoreV2/tensor_names, Shape: (16,)\n",
      "Layer: save/RestoreV2/shape_and_slices, Shape: (16,)\n",
      "Layer: save/RestoreV2, Shape: <unknown>\n",
      "Layer: save/Identity, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp, Shape: None\n",
      "Layer: save/Identity_1, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_1, Shape: None\n",
      "Layer: save/Identity_2, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_2, Shape: None\n",
      "Layer: save/Identity_3, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_3, Shape: None\n",
      "Layer: save/Identity_4, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_4, Shape: None\n",
      "Layer: save/Identity_5, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_5, Shape: None\n",
      "Layer: save/Identity_6, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_6, Shape: None\n",
      "Layer: save/Identity_7, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_7, Shape: None\n",
      "Layer: save/Identity_8, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_8, Shape: None\n",
      "Layer: save/Identity_9, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_9, Shape: None\n",
      "Layer: save/Identity_10, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_10, Shape: None\n",
      "Layer: save/Identity_11, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_11, Shape: None\n",
      "Layer: save/Identity_12, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_12, Shape: None\n",
      "Layer: save/Identity_13, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_13, Shape: None\n",
      "Layer: save/Identity_14, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_14, Shape: None\n",
      "Layer: save/Identity_15, Shape: <unknown>\n",
      "Layer: save/AssignVariableOp_15, Shape: None\n",
      "Layer: save/restore_all, Shape: None\n"
     ]
    }
   ],
   "source": [
    "for layer, shape in layer_shape_dict.items():\n",
    "    print(f'Layer: {layer}, Shape: {shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import tf_slim as slim\n",
    "\n",
    "def get_weights():\n",
    "  return [\n",
    "    v for v in tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    if v.name.endswith('weights:0')\n",
    "    ]\n",
    "  \n",
    "def alexnet_v2(inputs,\n",
    "               num_classes=1000,\n",
    "               is_training=True,\n",
    "               dropout_keep_prob=0.5,\n",
    "               spatial_squeeze=True,\n",
    "               scope='alexnet_v2',\n",
    "               global_pool=False,\n",
    "               reuse_variables=tf.compat.v1.AUTO_REUSE,\n",
    "               data_format='NHWC'\n",
    "               ):\n",
    "  \"\"\"AlexNet version 2.\n",
    "  Described in: http://arxiv.org/pdf/1404.5997v2.pdf\n",
    "  Parameters from:\n",
    "  github.com/akrizhevsky/cuda-convnet2/blob/master/layers/\n",
    "  layers-imagenet-1gpu.cfg\n",
    "  Note: All the fully_connected layers have been transformed to conv2d layers.\n",
    "        To use in classification mode, resize input to 224x224 or set\n",
    "        global_pool=True. To use in fully convolutional mode, set\n",
    "        spatial_squeeze to false.\n",
    "        The LRN layers have been removed and change the initializers from\n",
    "        random_normal_initializer to xavier_initializer.\n",
    "  Args:\n",
    "    inputs: a tensor of size [batch_size, height, width, channels].\n",
    "    num_classes: the number of predicted classes. If 0 or None, the logits layer\n",
    "    is omitted and the input features to the logits layer are returned instead.\n",
    "    is_training: whether or not the model is being trained.\n",
    "    dropout_keep_prob: the probability that activations are kept in the dropout\n",
    "      layers during training.\n",
    "    spatial_squeeze: whether or not should squeeze the spatial dimensions of the\n",
    "      logits. Useful to remove unnecessary dimensions for classification.\n",
    "    scope: Optional scope for the variables.\n",
    "    global_pool: Optional boolean flag. If True, the input to the classification\n",
    "      layer is avgpooled to size 1x1, for any input size. (This is not part\n",
    "      of the original AlexNet.)\n",
    "  Returns:\n",
    "    net: the output of the logits layer (if num_classes is a non-zero integer),\n",
    "      or the non-dropped-out input to the logits layer (if num_classes is 0\n",
    "      or None).\n",
    "    end_points: a dict of tensors with intermediate activations.\n",
    "  \"\"\"\n",
    "  act = []\n",
    "  with tf.compat.v1.variable_scope(scope, 'alexnet_v2', [inputs], reuse=reuse_variables) as sc:\n",
    "    end_points_collection = sc.original_name_scope + '_end_points'\n",
    "    # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                        outputs_collections=[end_points_collection], data_format=data_format):\n",
    "      net = slim.conv2d(inputs, 64, [11, 11], 4, padding='VALID',\n",
    "                        scope='conv1')\n",
    "      act.append(net)\n",
    "      net = slim.max_pool2d(net, [3, 3], 2, scope='pool1')\n",
    "      net = slim.conv2d(net, 192, [5, 5], scope='conv2')\n",
    "      act.append(net)\n",
    "      net = slim.max_pool2d(net, [3, 3], 2, scope='pool2')\n",
    "      net = slim.conv2d(net, 384, [3, 3], scope='conv3')\n",
    "      act.append(net)\n",
    "      net = slim.conv2d(net, 384, [3, 3], scope='conv4')\n",
    "      act.append(net)\n",
    "      net = slim.conv2d(net, 256, [3, 3], scope='conv5')\n",
    "      act.append(net)\n",
    "      net = slim.max_pool2d(net, [3, 3], 2, scope='pool5')\n",
    "\n",
    "      # Use conv2d instead of fully_connected layers.\n",
    "      with slim.arg_scope(\n",
    "          [slim.conv2d],\n",
    "          weights_initializer=trunc_normal(0.005),\n",
    "          biases_initializer=tf.constant_initializer(0.1)):\n",
    "        net = slim.conv2d(net, 4096, [5, 5], padding='VALID',\n",
    "                          scope='fc6')\n",
    "        net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                           scope='dropout6')\n",
    "        act.append(net)\n",
    "        net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "        act.append(net)\n",
    "        # Convert end_points_collection into a end_point dict.\n",
    "        end_points = slim.utils.convert_collection_to_dict(\n",
    "            end_points_collection)\n",
    "        if global_pool:\n",
    "          net = tf.reduce_mean(\n",
    "              input_tensor=net, axis=[1, 2], keepdims=True, name='global_pool')\n",
    "          end_points['global_pool'] = net\n",
    "        if num_classes:\n",
    "          net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                             scope='dropout7')\n",
    "          net = slim.conv2d(\n",
    "              net,\n",
    "              num_classes, [1, 1],\n",
    "              activation_fn=None,\n",
    "              normalizer_fn=None,\n",
    "              biases_initializer=tf.zeros_initializer(),\n",
    "              scope='fc8')\n",
    "          if spatial_squeeze:\n",
    "            squeeze_dims = [2, 3] if data_format == 'NCHW' else [1, 2]\n",
    "            net = tf.squeeze(net, squeeze_dims, name='fc8/squeezed')\n",
    "          readout = net\n",
    "          end_points[sc.name + '/fc8'] = net\n",
    "      return readout, act, get_weights()\n",
    "alexnet_v2.default_image_size = 224\n",
    "\n",
    "\n",
    "trunc_normal = lambda stddev: tf.compat.v1.truncated_normal_initializer(\n",
    "    0.0, stddev)\n",
    "\n",
    "\n",
    "def alexnet_v2_arg_scope(weight_decay=0.0005):\n",
    "  with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                      activation_fn=tf.nn.relu,\n",
    "                      biases_initializer=tf.constant_initializer(0.1),\n",
    "                      weights_regularizer=slim.l2_regularizer(weight_decay)):\n",
    "    with slim.arg_scope([slim.conv2d], padding='SAME'):\n",
    "      with slim.arg_scope([slim.max_pool2d], padding='VALID') as arg_sc:\n",
    "        return arg_sc\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_weights(session, checkpoint_path):\n",
    "  variables_to_restore = slim.get_model_variables('alexnet_v2')\n",
    "  saver = tf.compat.v1.train.Saver(variables_to_restore)\n",
    "  saver.restore(session, checkpoint_path)\n",
    "  print(\"Model loaded from:\", checkpoint_path)\n",
    "\n",
    "\n",
    "  \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "inputs = tf.compat.v1.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "with slim.arg_scope(alexnet_v2_arg_scope()):\n",
    "  logits, activations, weights = alexnet_v2(inputs, is_training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()\n",
    "def create_model_session(model_checkpoint_dir, model_checkpoint):\n",
    "    sess = tf.compat.v1.Session()\n",
    "    sess.run(init)\n",
    "    load_pretrained_weights(sess, os.path.join(model_checkpoint_dir, model_checkpoint))\n",
    "    return sess\n",
    "sess = create_model_session(model_checkpoint_dir, model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.compat.v1.get_default_graph()\n",
    "layer_name_list = [node.name for node in graph.as_graph_def().node if 'input' not in node.name]\n",
    "\n",
    "# Dictionary to hold layer names and their shapes\n",
    "layer_shape_dict = {}\n",
    "\n",
    "# Get the shape of each tensor in the graph\n",
    "for layer_name in layer_name_list:\n",
    "    try:\n",
    "        tensor = graph.get_tensor_by_name(f'{layer_name}:0')\n",
    "        tensor_shape = tensor.shape\n",
    "        if tensor_shape != ():\n",
    "            layer_shape_dict[layer_name] = tensor_shape\n",
    "    except KeyError:\n",
    "        layer_shape_dict[layer_name] = None\n",
    "\n",
    "# Print the layer shapes\n",
    "for layer, shape in layer_shape_dict.items():\n",
    "    print(f'Layer: {layer}, Shape: {shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucidenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
